{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This jupyter-notebook contains the evaluation of synthetic data generated using CTAB-GAN for the Adult dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the model\n",
    "from model.ctabgan import CTABGAN\n",
    "# Importing the evaluation metrics \n",
    "from model.eval.evaluation import get_utility_metrics,stat_sim,privacy_metrics\n",
    "# Importing standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "label = LabelEncoder()\n",
    "\n",
    "data = pd.read_csv(\"cicids2017.csv\")\n",
    "# data[data.columns[:-1]] = scaler.fit_transform(data[data.columns[:-1]])\n",
    "data[data.columns[:-1]] = np.array(data[data.columns[:-1]], dtype=float)\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.iloc[:, -1] = label.fit_transform(data.iloc[:, -1])\n",
    "data.dropna(inplace=True)\n",
    "data.head(3).T\n",
    "data.to_csv(\"Clean_2017data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_continuous_columns(dataframe, max_unique_values=20):\n",
    "    \"\"\"\n",
    "    Hàm để xác định các cột continuous, loại bỏ các cột có giá trị rời rạc như 0, 1 hoặc chỉ có 1-2 giá trị.\n",
    "    - dataframe: DataFrame chứa dữ liệu\n",
    "    - max_unique_values: Số lượng giá trị rời rạc tối đa để coi là continuous (mặc định là 3)\n",
    "    \"\"\"\n",
    "    continuous_columns = []\n",
    "    continuous_indices = []\n",
    "    \n",
    "    for col in dataframe.columns:\n",
    "        unique_values = dataframe[col].nunique()\n",
    "        # Loại bỏ các cột chỉ có giá trị rời rạc ít (như 0, 1 hoặc 0, 1, 2)\n",
    "        if dataframe[col].dtype in ['float64', 'int64'] and unique_values > max_unique_values:\n",
    "            continuous_columns.append(col)\n",
    "            continuous_indices.append(dataframe.columns.get_loc(col))\n",
    "    \n",
    "    return continuous_columns, continuous_indices\n",
    "\n",
    "# Ví dụ với dataset của bạn\n",
    "continuous_columns, continuous_indices = get_continuous_columns(data)\n",
    "\n",
    "print(\"Continuous Columns:\", continuous_columns)\n",
    "print(\"Indices of Continuous Columns:\", continuous_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the replication number \n",
    "num_exp = 1 \n",
    "# Specifying the name of the dataset used \n",
    "dataset = \"2020\" \n",
    "# Specifying the path of the dataset used \n",
    "real_path = \"iotid20.csv\" \n",
    "# Specifying the root directory for storing generated data\n",
    "fake_file_root = \"Fake_Datasets\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the synthesizer object and specifying input parameters\n",
    "# Notice: If you have continuous variable, you do not need to explicitly assign it. It will be treated like \n",
    "# that by default\n",
    "synthesizer =  CTABGAN(raw_csv_path = real_path,\n",
    "                 test_ratio = 0.20,  \n",
    "                 categorical_columns = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                                        'relationship', 'race', 'gender', 'native-country', 'income'], \n",
    "                 log_columns = [],\n",
    "                 mixed_columns= {'capital-loss':[0.0],'capital-gain':[0.0]}, \n",
    "                 integer_columns = ['age', 'fnlwgt','capital-gain', 'capital-loss','hours-per-week'],\n",
    "                 problem_type= {\"Classification\": 'income'},\n",
    "                 epochs = 150) \n",
    "\n",
    "# Fitting the synthesizer to the training dataset and generating synthetic data\n",
    "for i in range(num_exp):\n",
    "    synthesizer.fit()\n",
    "    syn = synthesizer.generate_samples()\n",
    "    syn.to_csv(fake_file_root+\"/\"+dataset+\"/\"+ dataset+\"_fake_{exp}.csv\".format(exp=i), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(fake_file_root+\"/\"+dataset+\"/\"+\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Utility Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>1.064592</td>\n",
       "      <td>0.009517</td>\n",
       "      <td>0.061383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>6.285188</td>\n",
       "      <td>0.063739</td>\n",
       "      <td>0.071529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>2.589825</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>0.040049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>2.763845</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.126618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>2.896919</td>\n",
       "      <td>0.049234</td>\n",
       "      <td>0.124052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Acc       AUC  F1_Score\n",
       "lr   1.064592  0.009517  0.061383\n",
       "dt   6.285188  0.063739  0.071529\n",
       "rf   2.589825  0.027153  0.040049\n",
       "mlp  2.763845  0.013811  0.126618\n",
       "svm  2.896919  0.049234  0.124052"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying the list of classifiers to conduct ML utility evaluation\n",
    "classifiers_list = continuous_columns\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Similarity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average WD (Continuous Columns</th>\n",
       "      <th>Average JSD (Categorical Columns)</th>\n",
       "      <th>Correlation Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.761534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
       "0                        0.009362                             0.1204   \n",
       "\n",
       "   Correlation Distance  \n",
       "0              0.761534  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Specifying the categorical columns of the dataset used\n",
    "# adult_categorical = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "\n",
    "# # Storing and presenting the results as a dataframe\n",
    "# stat_res_avg = []\n",
    "# for fake_path in fake_paths:\n",
    "#     stat_res = stat_sim(real_path,fake_path,adult_categorical)\n",
    "#     stat_res_avg.append(stat_res)\n",
    "\n",
    "# stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "# stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "# stat_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbour Privacy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DCR between Real and Fake (5th perc)</th>\n",
       "      <th>DCR within Real(5th perc)</th>\n",
       "      <th>DCR within Fake (5th perc)</th>\n",
       "      <th>NNDR between Real and Fake (5th perc)</th>\n",
       "      <th>NNDR within Real (5th perc)</th>\n",
       "      <th>NNDR within Fake (5th perc)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.485676</td>\n",
       "      <td>0.216545</td>\n",
       "      <td>0.22867</td>\n",
       "      <td>0.632722</td>\n",
       "      <td>0.442052</td>\n",
       "      <td>0.431408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
       "0                              0.485676                   0.216545   \n",
       "\n",
       "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
       "0                     0.22867                               0.632722   \n",
       "\n",
       "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
       "0                     0.442052                     0.431408  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Storing and presenting the results as a dataframe\n",
    "# priv_res_avg = []\n",
    "# for fake_path in fake_paths:\n",
    "#     priv_res = privacy_metrics(real_path,fake_path)\n",
    "#     priv_res_avg.append(priv_res)\n",
    "    \n",
    "# privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "# privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "# privacy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing generated data for future use if needed\n",
    "syn.to_csv(fake_file_root+\"/\"+dataset+\"/\"+ dataset+\"_fake_{exp}.csv\".format(exp=i), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5bbd4e8a0020626d1955d6e7d647b883363040a056d10513dec12a340be08610"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
